#!/usr/bin/env python3
"""
Comprehensive pipeline verification script.
Checks all claimed components are implemented and working.
"""

import sys
from pathlib import Path
import torch
import json
import os

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

print("=" * 80)
print("  PIPELINE VERIFICATION CHECKLIST")
print("=" * 80)
print()

checks = {
    "1. GemNet Architecture": {"status": "PENDING", "details": []},
    "2. FiLM Domain Adaptation": {"status": "PENDING", "details": []},
    "3. LoRA Adapters": {"status": "PENDING", "details": []},
    "4. Ensemble Uncertainty": {"status": "PENDING", "details": []},
    "5. Gate-Hard Ranking": {"status": "PENDING", "details": []},
    "6. Delta Head (Quantum Corrections)": {"status": "PENDING", "details": []},
    "7. Quantum DMET+VQE": {"status": "PENDING", "details": []},
    "8. Trained Models": {"status": "PENDING", "details": []},
    "9. Evaluation Pipeline": {"status": "PENDING", "details": []},
    "10. Main Pipeline Integration": {"status": "PENDING", "details": []},
}

# 1. Check GemNet Architecture
print("üîç 1. Checking GemNet Architecture...")
try:
    from gnn.model_gemnet import GemNetWrapper, FiLMLayer, DomainEmbedding
    checks["1. GemNet Architecture"]["status"] = "‚úÖ PASS"
    checks["1. GemNet Architecture"]["details"].append("GemNetWrapper class found")
    checks["1. GemNet Architecture"]["details"].append("FiLMLayer class found")
    checks["1. GemNet Architecture"]["details"].append("DomainEmbedding class found")
except ImportError as e:
    checks["1. GemNet Architecture"]["status"] = "‚ùå FAIL"
    checks["1. GemNet Architecture"]["details"].append(f"Import error: {e}")

# 2. Check FiLM in GemNet
print("üîç 2. Checking FiLM Domain Adaptation...")
try:
    from gnn.model_gemnet import GemNetWrapper
    model = GemNetWrapper(use_film=True, num_domains=5, film_dim=16)
    if hasattr(model, 'domain_embedding') and model.domain_embedding is not None:
        checks["2. FiLM Domain Adaptation"]["status"] = "‚úÖ PASS"
        checks["2. FiLM Domain Adaptation"]["details"].append("FiLM enabled in GemNetWrapper")
        checks["2. FiLM Domain Adaptation"]["details"].append(f"Domain embedding: {type(model.domain_embedding)}")
        checks["2. FiLM Domain Adaptation"]["details"].append(f"Output layer has FiLM: {hasattr(model.output, 'film_layer')}")
    else:
        checks["2. FiLM Domain Adaptation"]["status"] = "‚ö†Ô∏è  WARNING"
        checks["2. FiLM Domain Adaptation"]["details"].append("FiLM not enabled by default")
except Exception as e:
    checks["2. FiLM Domain Adaptation"]["status"] = "‚ùå FAIL"
    checks["2. FiLM Domain Adaptation"]["details"].append(f"Error: {e}")

# 3. Check LoRA in GemNet
print("üîç 3. Checking LoRA Adapters...")
try:
    from gnn.model_gemnet import GemNetWrapper
    model = GemNetWrapper()
    if hasattr(model, 'lora') or any('lora' in name.lower() for name, _ in model.named_modules()):
        checks["3. LoRA Adapters"]["status"] = "‚úÖ PASS"
        checks["3. LoRA Adapters"]["details"].append("LoRA found in GemNet model")
    else:
        # Check if LoRA exists in domain_aware_model
        try:
            from gnn.domain_aware_model import LoRALayer
            checks["3. LoRA Adapters"]["status"] = "‚ö†Ô∏è  WARNING"
            checks["3. LoRA Adapters"]["details"].append("LoRA exists but NOT in GemNet (only in SchNet domain_aware_model)")
            checks["3. LoRA Adapters"]["details"].append("LoRA is in domain_aware_model.py, not GemNetWrapper")
        except ImportError:
            checks["3. LoRA Adapters"]["status"] = "‚ùå FAIL"
            checks["3. LoRA Adapters"]["details"].append("LoRA not found anywhere")
except Exception as e:
    checks["3. LoRA Adapters"]["status"] = "‚ùå FAIL"
    checks["3. LoRA Adapters"]["details"].append(f"Error: {e}")

# 4. Check Ensemble Uncertainty
print("üîç 4. Checking Ensemble Uncertainty...")
try:
    from gnn.uncertainty import EnsembleUncertainty
    checks["4. Ensemble Uncertainty"]["status"] = "‚úÖ PASS"
    checks["4. Ensemble Uncertainty"]["details"].append("EnsembleUncertainty class found")
    
    # Check for ensemble model checkpoints
    ensemble_dirs = list(Path("artifacts").glob("*ensemble*")) if Path("artifacts").exists() else []
    if ensemble_dirs:
        checks["4. Ensemble Uncertainty"]["details"].append(f"Found ensemble artifacts: {len(ensemble_dirs)}")
    else:
        checks["4. Ensemble Uncertainty"]["details"].append("No ensemble model checkpoints found")
except ImportError as e:
    checks["4. Ensemble Uncertainty"]["status"] = "‚ùå FAIL"
    checks["4. Ensemble Uncertainty"]["details"].append(f"Import error: {e}")

# 5. Check Gate-Hard Ranking
print("üîç 5. Checking Gate-Hard Ranking...")
try:
    from pipeline.gate_hard_ranking import GateHardRanker, DomainRankingConfig
    checks["5. Gate-Hard Ranking"]["status"] = "‚úÖ PASS"
    checks["5. Gate-Hard Ranking"]["details"].append("GateHardRanker class found")
    
    # Check for gate-hard artifacts
    gate_hard_dirs = list(Path("artifacts").glob("*gate*hard*")) if Path("artifacts").exists() else []
    if gate_hard_dirs:
        checks["5. Gate-Hard Ranking"]["details"].append(f"Found gate-hard artifacts: {len(gate_hard_dirs)}")
except ImportError as e:
    checks["5. Gate-Hard Ranking"]["status"] = "‚ùå FAIL"
    checks["5. Gate-Hard Ranking"]["details"].append(f"Import error: {e}")

# 6. Check Delta Head
print("üîç 6. Checking Delta Head...")
try:
    from dft_hybrid.distill.delta_head import DeltaHead, DeltaHeadTrainer
    checks["6. Delta Head (Quantum Corrections)"]["status"] = "‚úÖ PASS"
    checks["6. Delta Head (Quantum Corrections)"]["details"].append("DeltaHead class found")
    
    # Check for trained delta head
    delta_path = Path("artifacts/delta_head.pt")
    if delta_path.exists():
        checks["6. Delta Head (Quantum Corrections)"]["details"].append("Trained delta head checkpoint found")
        try:
            ckpt = torch.load(delta_path, map_location='cpu', weights_only=False)
            checks["6. Delta Head (Quantum Corrections)"]["details"].append(f"Checkpoint keys: {list(ckpt.keys())[:5]}")
        except:
            pass
    else:
        checks["6. Delta Head (Quantum Corrections)"]["details"].append("‚ö†Ô∏è  No trained delta head checkpoint found")
except ImportError as e:
    checks["6. Delta Head (Quantum Corrections)"]["status"] = "‚ùå FAIL"
    checks["6. Delta Head (Quantum Corrections)"]["details"].append(f"Import error: {e}")

# 7. Check Quantum DMET+VQE
print("üîç 7. Checking Quantum DMET+VQE...")
try:
    from dft_hybrid.dmet.fragment import QuantumFragmentLabeler, FragmentGenerator
    checks["7. Quantum DMET+VQE"]["status"] = "‚úÖ PASS"
    checks["7. Quantum DMET+VQE"]["details"].append("QuantumFragmentLabeler class found")
    checks["7. Quantum DMET+VQE"]["details"].append("FragmentGenerator class found")
    
    # Check if Qiskit is available
    try:
        import qiskit
        checks["7. Quantum DMET+VQE"]["details"].append(f"Qiskit available: {qiskit.__version__}")
    except ImportError:
        checks["7. Quantum DMET+VQE"]["details"].append("‚ö†Ô∏è  Qiskit not available")
        
    # Check for quantum labels
    qnn_labels = Path("artifacts/quantum_labels_gate_hard.csv")
    if qnn_labels.exists():
        checks["7. Quantum DMET+VQE"]["details"].append("Quantum labels CSV found")
        import pandas as pd
        df = pd.read_csv(qnn_labels)
        checks["7. Quantum DMET+VQE"]["details"].append(f"Quantum labels: {len(df)} samples")
except ImportError as e:
    checks["7. Quantum DMET+VQE"]["status"] = "‚ùå FAIL"
    checks["7. Quantum DMET+VQE"]["details"].append(f"Import error: {e}")
except Exception as e:
    checks["7. Quantum DMET+VQE"]["status"] = "‚ö†Ô∏è  WARNING"
    checks["7. Quantum DMET+VQE"]["details"].append(f"Error checking labels: {e}")

# 8. Check Trained Models
print("üîç 8. Checking Trained Models...")
model_paths = {
    "GemNet with FiLM": Path("models/gemnet_per_atom_film/best_model.pt"),
    "Delta Head": Path("artifacts/delta_head.pt"),
}
all_found = True
for name, path in model_paths.items():
    if path.exists():
        checks["8. Trained Models"]["details"].append(f"‚úÖ {name}: {path}")
        try:
            ckpt = torch.load(path, map_location='cpu', weights_only=False)
            size_mb = path.stat().st_size / (1024 * 1024)
            checks["8. Trained Models"]["details"].append(f"   Size: {size_mb:.1f} MB")
        except Exception as e:
            checks["8. Trained Models"]["details"].append(f"   ‚ö†Ô∏è  Error loading: {e}")
    else:
        checks["8. Trained Models"]["details"].append(f"‚ùå {name}: NOT FOUND at {path}")
        all_found = False

if all_found:
    checks["8. Trained Models"]["status"] = "‚úÖ PASS"
else:
    checks["8. Trained Models"]["status"] = "‚ö†Ô∏è  WARNING"

# 9. Check Evaluation Pipeline
print("üîç 9. Checking Evaluation Pipeline...")
eval_script = Path("scripts/evaluate_gemnet_film.py")
if eval_script.exists():
    checks["9. Evaluation Pipeline"]["status"] = "‚úÖ PASS"
    checks["9. Evaluation Pipeline"]["details"].append(f"Evaluation script found: {eval_script}")
    
    # Check if evaluation was run
    eval_log = Path("logs/evaluate_gemnet_film_full.log")
    if eval_log.exists():
        checks["9. Evaluation Pipeline"]["details"].append("Evaluation log found")
        with open(eval_log, 'r') as f:
            content = f.read()
            if "MAE" in content and "R¬≤" in content:
                checks["9. Evaluation Pipeline"]["details"].append("Evaluation results found in log")
else:
    checks["9. Evaluation Pipeline"]["status"] = "‚ùå FAIL"
    checks["9. Evaluation Pipeline"]["details"].append("Evaluation script not found")

# 10. Check Main Pipeline Integration
print("üîç 10. Checking Main Pipeline Integration...")
try:
    from pipeline.run import HybridPipeline
    checks["10. Main Pipeline Integration"]["status"] = "‚úÖ PASS"
    checks["10. Main Pipeline Integration"]["details"].append("HybridPipeline class found")
    
    # Check if pipeline has all methods
    pipeline_methods = ['load_data', 'train_gnn_surrogate', 'estimate_uncertainty', 'apply_delta_head']
    for method in pipeline_methods:
        if hasattr(HybridPipeline, method):
            checks["10. Main Pipeline Integration"]["details"].append(f"‚úÖ {method}() method exists")
        else:
            checks["10. Main Pipeline Integration"]["details"].append(f"‚ùå {method}() method missing")
            checks["10. Main Pipeline Integration"]["status"] = "‚ö†Ô∏è  WARNING"
except ImportError as e:
    checks["10. Main Pipeline Integration"]["status"] = "‚ùå FAIL"
    checks["10. Main Pipeline Integration"]["details"].append(f"Import error: {e}")

# Print summary
print()
print("=" * 80)
print("  VERIFICATION SUMMARY")
print("=" * 80)
print()

for check_name, check_data in checks.items():
    status = check_data["status"]
    details = check_data["details"]
    
    print(f"{status} {check_name}")
    for detail in details:
        print(f"   {detail}")
    print()

# Overall assessment
pass_count = sum(1 for c in checks.values() if c["status"] == "‚úÖ PASS")
warn_count = sum(1 for c in checks.values() if c["status"] == "‚ö†Ô∏è  WARNING")
fail_count = sum(1 for c in checks.values() if c["status"] == "‚ùå FAIL")

print("=" * 80)
print(f"Overall: {pass_count} ‚úÖ | {warn_count} ‚ö†Ô∏è  | {fail_count} ‚ùå")
print("=" * 80)

# Issues to address
print()
if warn_count > 0 or fail_count > 0:
    print("‚ö†Ô∏è  ISSUES TO ADDRESS:")
    print()
    for check_name, check_data in checks.items():
        if check_data["status"] in ["‚ö†Ô∏è  WARNING", "‚ùå FAIL"]:
            print(f"   {check_name}: {check_data['status']}")
            for detail in check_data["details"]:
                if "‚ö†Ô∏è" in detail or "‚ùå" in detail:
                    print(f"      - {detail}")
else:
    print("‚úÖ All checks passed! Pipeline is fully implemented.")



