#!/usr/bin/env python3
"""
Integrate New Trained GemNet Model into Full Pipeline
This script updates all downstream components to use the new model.
"""

import sys
import os
from pathlib import Path
import logging
import torch
import json
import numpy as np

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from gnn.model_gemnet import GemNetWrapper
from torch_geometric.data import Data, Batch
from tqdm import tqdm

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)


class UpdatedPipeline:
    """Pipeline updated to use GemNet model."""
    
    def __init__(self, model_path: str):
        """Initialize pipeline with GemNet model.
        
        Args:
            model_path: Path to trained GemNet model checkpoint
        """
        self.model_path = Path(model_path)
        self.model = self._load_model()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"Using device: {self.device}")
        
    def _load_model(self):
        """Load trained GemNet model."""
        logger.info(f"Loading GemNet model from: {self.model_path}")
        
        if not self.model_path.exists():
            raise FileNotFoundError(f"Model not found: {self.model_path}")
        
        checkpoint = torch.load(self.model_path, map_location='cpu')
        
        # Get model config from checkpoint
        model_config = checkpoint.get('model_config', {
            'num_atoms': 95,
            'hidden_dim': 256,
            'num_interactions': 6,
            'cutoff': 10.0,
            'mean': None,
            'std': None
        })
        
        logger.info(f"   Model config: {model_config}")
        
        # Initialize model with saved config
        model = GemNetWrapper(**model_config)
        
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        logger.info("‚úÖ GemNet model loaded successfully")
        return model
    
    def predict_with_gemnet(self, samples: list) -> list:
        """Generate predictions using GemNet model.
        
        Args:
            samples: List of sample dictionaries with atomic structure
            
        Returns:
            List of prediction dictionaries
        """
        logger.info(f"üîÆ Generating predictions for {len(samples)} samples")
        
        predictions = []
        self.model = self.model.to(self.device)
        
        with torch.no_grad():
            for sample in tqdm(samples, desc="Predicting"):
                try:
                    # Convert to PyG Data
                    data = self._sample_to_data(sample)
                    data = data.to(self.device)
                    
                    # Predict with GemNet (returns tuple: energy, forces, stress)
                    output = self.model(data)
                    if isinstance(output, tuple):
                        energy_pred = output[0].item()  # Extract energy
                    else:
                        energy_pred = output.item()
                    
                    pred_dict = {
                        'sample_id': sample.get('sample_id', 'unknown'),
                        'domain': sample.get('domain', 'jarvis_dft'),
                        'num_atoms': sample['num_atoms'],
                        'energy_pred': energy_pred,
                        'energy_target': sample.get('energy', sample.get('energy_target', 0.0)),
                        'energy_variance': self._estimate_variance(energy_pred, sample),
                        'atomic_numbers': sample['atomic_numbers'],
                        'positions': sample['positions'],
                        'forces_pred': [[0.0, 0.0, 0.0]] * sample['num_atoms'],
                        'tm_flag': self._is_transition_metal(sample['atomic_numbers']),
                        'near_degeneracy_proxy': 0.0
                    }
                    
                    predictions.append(pred_dict)
                    
                except Exception as e:
                    logger.warning(f"Failed to predict sample: {e}")
                    continue
        
        logger.info(f"   Generated {len(predictions)} successful predictions")
        return predictions
    
    def _sample_to_data(self, sample: dict) -> Data:
        """Convert sample dictionary to PyG Data object."""
        atomic_numbers = torch.tensor(sample['atomic_numbers'], dtype=torch.long)
        positions = torch.tensor(sample['positions'], dtype=torch.float32)
        
        return Data(
            atomic_numbers=atomic_numbers,
            pos=positions,
            batch=torch.zeros(len(atomic_numbers), dtype=torch.long)
        )
    
    def _estimate_variance(self, energy_pred: float, sample: dict) -> float:
        """Estimate prediction variance (placeholder)."""
        # In real implementation, would compute from ensemble
        return abs(energy_pred * 0.1)  # 10% estimate
    
    def _is_transition_metal(self, atomic_numbers: list) -> bool:
        """Check if structure contains transition metals."""
        # Transition metals (Sc through Zn, Y through Cd, La through Hg)
        tm_z = set(range(21, 31)) | set(range(39, 49)) | set(range(57, 81)) | set([71, 72, 73, 74, 75, 76, 77, 78, 79, 80])
        return any(z in tm_z for z in atomic_numbers)


def generate_updated_ensemble_predictions():
    """Generate ensemble predictions using new GemNet model."""
    logger.info("üöÄ STARTING PIPELINE UPDATE")
    logger.info("="*80)
    
    # 1. Load model
    model_path = "models/gemnet_full/best_model.pt"
    pipeline = UpdatedPipeline(model_path)
    
    # 2. Load test data
    data_path = Path("data/preprocessed_full_unified/test_data.json")
    
    logger.info(f"üì• Loading test data from: {data_path}")
    with open(data_path, 'r') as f:
        test_samples = json.load(f)
    
    logger.info(f"   Loaded {len(test_samples)} test samples")
    
    # 3. Generate predictions for ALL samples to get top 270 hard cases
    logger.info("\nüîÆ GENERATING PREDICTIONS")
    logger.info("="*80)
    logger.info(f"   Generating predictions for ALL {len(test_samples)} test samples")
    logger.info("   This will take a few minutes...")
    
    # Use all samples to ensure we have enough for top 270
    predictions = pipeline.predict_with_gemnet(test_samples)
    
    # 4. Save predictions
    output_path = Path("artifacts/gemnet_predictions")
    output_path.mkdir(parents=True, exist_ok=True)
    
    with open(output_path / 'ensemble_predictions.json', 'w') as f:
        json.dump(predictions, f, indent=2)
    
    logger.info(f"\n‚úÖ Predictions saved to: {output_path / 'ensemble_predictions.json'}")
    logger.info(f"   Total predictions: {len(predictions)}")
    
    # 5. Summary statistics
    logger.info("\nüìä PREDICTION STATISTICS")
    logger.info("="*80)
    
    if predictions:
        energies = [p['energy_pred'] for p in predictions]
        targets = [p['energy_target'] for p in predictions]
        
        mae = np.mean(np.abs(np.array(energies) - np.array(targets)))
        mae_per_atom = mae / np.mean([p['num_atoms'] for p in predictions])
        
        logger.info(f"   MAE (total energy): {mae:.4f}")
        logger.info(f"   MAE (per atom): {mae_per_atom:.4f}")
        logger.info(f"   Energy range: [{min(energies):.2f}, {max(energies):.2f}]")
    
    logger.info("\n‚úÖ PIPELINE READY FOR DOWNSTREAM COMPONENTS")
    logger.info("="*80)
    logger.info("   ‚úì GemNet model loaded")
    logger.info("   ‚úì Predictions generated")
    logger.info("   ‚úì Ready for gate-hard ranking")
    logger.info("   ‚úì Ready for quantum labeling")
    logger.info("   ‚úì Ready for delta head training")
    
    return predictions


if __name__ == "__main__":
    predictions = generate_updated_ensemble_predictions()
    
    logger.info("\nüìÅ OUTPUT:")
    logger.info("   artifacts/gemnet_predictions/ensemble_predictions.json")
    logger.info("\nüéØ NEXT:")
    logger.info("   Use these predictions for:")
    logger.info("   - Gate-hard ranking")
    logger.info("   - Quantum labeling")
    logger.info("   - Delta head training")

